{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Penn Treebank Corpus is a widely used annotated dataset in natural language processing research. It consists of text samples from various sources, including newspaper articles, fiction, non-fiction, and transcribed speech. Each word in the corpus is manually annotated with its corresponding part-of-speech tag, providing valuable linguistic information for tasks such as syntactic analysis, parsing, and information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download the treebank corpus\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the tagged sentences\n",
    "tagged_sentences = list(treebank.tagged_sents())\n",
    "\n",
    "#We need to mark the beginning of a sentence, so we will use the token <s> tagged as <s>\n",
    "for sentence in tagged_sentences:\n",
    "    sentence.insert(0, ('--s--', '--s--'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  3131\n",
      "Test data size:  783\n"
     ]
    }
   ],
   "source": [
    "#Split the data into training and test data\n",
    "DATA_size = len(tagged_sentences)\n",
    "\n",
    "train_data = tagged_sentences[:int(DATA_size * 0.8)]\n",
    "test_data = tagged_sentences[int(DATA_size * 0.8):]\n",
    "\n",
    "print(\"Train data size: \", len(train_data))\n",
    "print(\"Test data size: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  11045\n",
      "Tags size:  47\n"
     ]
    }
   ],
   "source": [
    "#Create the vocabulary and tags set\n",
    "vocab = set()\n",
    "tags = set()\n",
    "\n",
    "#Get the vocabulary\n",
    "for sentence in train_data:\n",
    "    for word, tag in sentence:\n",
    "        vocab.add(word)\n",
    "        tags.add(tag)\n",
    "\n",
    "#sort tags\n",
    "tags = sorted(tags)\n",
    "\n",
    "print(\"Vocabulary size: \", len(vocab))\n",
    "print(\"Tags size: \", len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to map words and tags to unique indices\n",
    "vocab_dict = {word: i for i, word in enumerate(vocab)}\n",
    "tags_dict = {tag: i for i, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training corpus size:  83768\n"
     ]
    }
   ],
   "source": [
    "# Create a training corpus\n",
    "training_corpus = list(chain(*train_data))\n",
    "print(\"Training corpus size: \", len(training_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Generating Transition and Emission Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to compute :\n",
    "\n",
    "* Transition counts : $C(t_i/t_{i-1})$\n",
    "* Emission counts : $C(w_i/t_i)$\n",
    "\n",
    "And we will also need a tag counts for smoothing :\n",
    "* Tag counts : $C(t_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_counts(training_corpus):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        - training_corpus: a corpus where each word is tagged. Each word is a tuple of (word, tag).\n",
    "    output:\n",
    "        - transition_counts: a dictionary where the keys are tuples that represent a part of speech, and the values are the counts of each part of speech.\n",
    "        - emission_counts: a dictionary where the keys are tuples that represent a (tag, word) pair, and the values are the counts of each pair.\n",
    "        - tag_counts: a dictionary where the keys are the part of speech tags, and the values are the counts of each tag.\n",
    "    \"\"\"\n",
    "    #Transition_counts dictionary\n",
    "    transition_counts = defaultdict(int)\n",
    "    emission_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "\n",
    "    prev_tag = '--s--' #start symbol\n",
    "\n",
    "    for w,tag in training_corpus:\n",
    "        transition_counts[(prev_tag,tag)] += 1\n",
    "        emission_counts[(w, tag)] += 1\n",
    "        tag_counts[tag] += 1\n",
    "        prev_tag = tag\n",
    "\n",
    "    return transition_counts, emission_counts, tag_counts\n",
    "\n",
    "transition_counts, emission_counts, tag_counts = create_counts(training_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate the transitions matrix A and the emission matrix. Note that we will need to apply smoothing to these.\n",
    "\n",
    "* Transition Matrix A : $$P(t_i/t_{i-1})=\\frac{C(t_{i-1},t_i)+\\alpha}{C(t_{i-1})+\\alpha*N}$$\n",
    "* Emission Matrix B : $$P(w_i/t_i)=\\frac{C(t_i,w_i)+\\alpha}{C(t_{i})+\\alpha*N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that computes the transition matrix A\n",
    "def transition_matrix(tag_counts, transition_counts,alpha=1e-2):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        - tag_counts: a dictionary where the keys are the part of speech tags, and the values are the counts of each tag.\n",
    "        - transition_counts: a dictionary where the keys are tuples that represent a part of speech, and the values are the counts of each part of speech.\n",
    "        - alpha: a smoothing parameter.\n",
    "    output:\n",
    "        - A: a matrix of dimension (num_tags, num_tags) representing the transition matrix of part of speech tags.\n",
    "    \"\"\"\n",
    "    num_tags = len(tag_counts)\n",
    "    A = np.zeros((num_tags, num_tags))\n",
    "\n",
    "    for tag,i in tags_dict.items():\n",
    "        for prev_tag,j in tags_dict.items():\n",
    "            A[i, j] = (transition_counts[(tag, prev_tag)]+alpha) / (tag_counts[prev_tag]+alpha*num_tags)\n",
    "\n",
    "    return A\n",
    "\n",
    "#Create the transition matrix\n",
    "A = transition_matrix(tag_counts, transition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>''</th>\n",
       "      <th>,</th>\n",
       "      <th>--s--</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.065148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.099509</td>\n",
       "      <td>0.392574</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--s--</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              #         $        ''         ,     --s--\n",
       "#      0.000691  0.000021  0.000016  0.000003  0.000003\n",
       "$      0.000691  0.000021  0.000016  0.000003  0.000003\n",
       "''     0.000691  0.000021  0.006505  0.000003  0.065148\n",
       ",      0.000691  0.099509  0.392574  0.000003  0.000323\n",
       "--s--  0.000691  0.010384  0.001638  0.000003  0.000323"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A[0:5,0:5], columns = list(tags_dict.keys())[0:5], index = list(tags_dict.keys())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>133.8</th>\n",
       "      <th>represented</th>\n",
       "      <th>Winiarski</th>\n",
       "      <th>overnight</th>\n",
       "      <th>2.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--s--</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          133.8  represented  Winiarski  overnight      2.25\n",
       "#      0.000080     0.000080   0.000080   0.000080  0.000080\n",
       "$      0.000017     0.000017   0.000017   0.000017  0.000017\n",
       "''     0.000014     0.000014   0.000014   0.000014  0.000014\n",
       ",      0.000002     0.000002   0.000002   0.000002  0.000002\n",
       "--s--  0.000003     0.000003   0.000003   0.000003  0.000003"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a function that computes the emission matrix B\n",
    "def emission_matrix(tag_counts, emission_counts, vocab,alpha=1e-2):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        - tag_counts: a dictionary where the keys are the part of speech tags, and the values are the counts of each tag.\n",
    "        - emission_counts: a dictionary where the keys are tuples that represent a (tag, word) pair, and the values are the counts of each pair.\n",
    "        - vocab: a dictionary where keys are words in the vocabulary and the value is the unique integer that represents the word.\n",
    "        - alpha: a smoothing parameter.\n",
    "    output:\n",
    "        - B: a matrix of dimension (num_tags, len(vocab)) representing the emission matrix of part of speech tags.\n",
    "    \"\"\"\n",
    "    num_tags = len(tag_counts)\n",
    "    num_words = len(vocab)\n",
    "    B = np.zeros((num_tags, num_words))\n",
    "\n",
    "    for tag,i in tags_dict.items():\n",
    "        for j, word in enumerate(vocab):\n",
    "            B[i, j] = (emission_counts[(word, tag)] +alpha)/ (tag_counts[tag]+alpha*num_words)\n",
    "\n",
    "    return B\n",
    "\n",
    "#Create the emission matrix\n",
    "B = emission_matrix(tag_counts, emission_counts, vocab)\n",
    "\n",
    "pd.DataFrame(B[0:5, 0:5], columns = list(vocab)[0:5], index = list(tags_dict.keys())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a matrix **best_probs**, where each cell $v_t(j)$ represent the probability that the HMM (with the parameters A and B represented by $\\lambda$) is in state j (unique ID of a tag) after seeing the first t observations $o_1,o_2,...,o_{t}$ and passing throught the most probable state sequence $q_1,q_2,...,q_{t-1}$, formally :\n",
    "\n",
    "$$v_t(j)=max_{q_1,q_2,...,q_{t-1}}P(q_1,q_2,...,q_{t-1},o_1,o_2,...,o_{t},q_t=j/\\lambda)$$\n",
    "\n",
    "\n",
    "The value of each cell $v_t(j)$ is computed by recursively taking the most porbable path that could lead us to this cell.\n",
    "\n",
    "Let's start by the first column $v_1(j)$ :\n",
    "\n",
    "\\begin{align*}\n",
    "v_1(j) &= P(o_1, q_1=j|\\lambda) \\\\\n",
    "&=P(o_1|\\lambda).P(q_1=j|\\lambda) \\\\\n",
    "(*) &= P(o_1/\\text{<s>})P(\\text{tags\\_dict[j]/<s>}) \\\\\n",
    "&= B[j,\\text{vocab\\_dict}[o_1]]A[j,0]\n",
    "\\end{align*}\n",
    "\n",
    "> (*) *Since $o_1$ is the $1^{st}$ observation then it will be preceded necessary by the tag \\<s>, which let us say that the tag of index j is also preceded by the tag \\<s>*\n",
    "\n",
    "\n",
    "We already computed A and B, so we can compute the first column of **best_path** matrix.\n",
    "\n",
    "Now recursively :\n",
    "\n",
    "\\begin{align*}\n",
    "v_t(j) &= max_{q_1,q_2,...,q_{t-1}}P(q_1,q_2,...,q_{t-1},o_1,o_2,...,o_{t},q_t=j/\\lambda) \\\\\n",
    "&= max_{q_{t-1}}max_{q_1,q_2,...,q_{t-2}}P(q_1,q_2,...,q_{t-2},o_1,o_2,...,o_{t-1},q_{t-1}/\\lambda).P(q_{t-1},o_t,q_t=j) \\\\\n",
    "&= max_{i=1}^Nmax_{q_1,q_2,...,q_{t-2}}P(q_1,q_2,...,q_{t-2},o_1,o_2,...,o_{t-1},q_{t-1}=i/\\lambda).P(q_{t-1}=i,q_t=j).P(o_t/q_t=j) \\\\\n",
    "&= max_{i=1}^Nv_{t-1}(i)A[j,i]B[j,\\text{vocab\\_dict}[o_t]]\n",
    "\\end{align*}\n",
    "\n",
    "To sum up :\n",
    "\\begin{align*}\n",
    "\\forall j\\in \\text{Tags\\_index    } v_t(j) &= max_{i=1}^Nv_{t-1}(i)A[j,i]B[j,\\text{vocab\\_dict}[o_t]] \\\\\n",
    "v_1(j) &= B[j,\\text{vocab\\_dict}[o_1]]A[j,0]\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its composed of three main stages :\n",
    "* Initialisation\n",
    "* Feed forward\n",
    "* Feed backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_1(j) = B[j,\\text{vocab\\_dict}[o_1]]A[j,0]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['I','feel','happy','today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-16.70632194, -18.26668439, -18.47058757, -20.19294357,\n",
       "       -19.96619395, -17.20274136, -20.46959415, -17.23166601,\n",
       "       -19.96031513, -18.27341333, -19.45618039, -19.75504454,\n",
       "       -20.68696062, -17.13704459, -16.62255596, -14.31903623,\n",
       "       -20.3706868 , -17.91178018, -17.42152227, -16.69825413,\n",
       "       -18.60799163, -21.12961563, -15.53074094, -17.55384936,\n",
       "       -20.40568263, -16.76104446, -18.48697131, -10.00372844,\n",
       "       -18.50840692, -19.6880759 , -17.32245183, -16.82726947,\n",
       "       -17.56071162, -16.59599397, -12.99340479, -16.61378012,\n",
       "       -19.56326307, -15.05486613, -19.05978039, -19.37375659,\n",
       "       -19.0263909 , -19.43803531, -17.99488254, -17.66762675,\n",
       "       -16.67365264, -17.44866097, -18.49102564])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize(tags_dict,A,B,vocab_dict,text):\n",
    "    num_tags = len(tags_dict)\n",
    "\n",
    "    #initialize best_probs\n",
    "    best_probs = np.zeros((num_tags,len(text)))\n",
    "\n",
    "    for j in range(num_tags):\n",
    "        best_probs[j,0] = math.log(B[j,vocab_dict[text[0]]])+math.log(A[j,0])\n",
    "\n",
    "    return best_probs\n",
    "\n",
    "best_probs = initialize(tags_dict,A,B,vocab_dict,text)\n",
    "best_probs[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Viterbi forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_t(j) = max_{i=1}^Nv_{t-1}(i)A[j,i]B[j,\\text{vocab\\_dict}[o_t]]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>feel</th>\n",
       "      <th>happy</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <td>-16.706322</td>\n",
       "      <td>-31.015501</td>\n",
       "      <td>-40.167702</td>\n",
       "      <td>-50.831571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>-18.266684</td>\n",
       "      <td>-32.400492</td>\n",
       "      <td>-41.469580</td>\n",
       "      <td>-48.857898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>''</th>\n",
       "      <td>-18.470588</td>\n",
       "      <td>-24.699711</td>\n",
       "      <td>-36.224858</td>\n",
       "      <td>-47.187489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>-20.192944</td>\n",
       "      <td>-25.147485</td>\n",
       "      <td>-35.522499</td>\n",
       "      <td>-47.635264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>--s--</th>\n",
       "      <td>-19.966194</td>\n",
       "      <td>-24.617661</td>\n",
       "      <td>-37.282667</td>\n",
       "      <td>-47.105440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               I       feel      happy      today\n",
       "#     -16.706322 -31.015501 -40.167702 -50.831571\n",
       "$     -18.266684 -32.400492 -41.469580 -48.857898\n",
       "''    -18.470588 -24.699711 -36.224858 -47.187489\n",
       ",     -20.192944 -25.147485 -35.522499 -47.635264\n",
       "--s-- -19.966194 -24.617661 -37.282667 -47.105440"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to handle unknown words in the vocabulary set\n",
    "def handle_unk_words(word):\n",
    "    if re.match(r'^[0-9\\W]+$', word):\n",
    "        return \"CD\"\n",
    "    if word[-2:]==\"er\":\n",
    "        return \"JJR\"\n",
    "    if word[-3:]==\"est\":\n",
    "        return \"JJS\"\n",
    "    if word[-2:]==\"ly\":\n",
    "        return \"RB\"\n",
    "    if word[-3:]==\"ing\":\n",
    "        return \"VBG\"\n",
    "    if word[-2:]==\"ed\":\n",
    "        return \"VBD\"\n",
    "    if word[-1:]==\"s\":\n",
    "        return \"NNS\"\n",
    "    if word[-2:] in [\"'s\",\"es\"]:\n",
    "        return \"VBZ\"\n",
    "    else :\n",
    "        return \"NN\"\n",
    "\n",
    "#Feed forward\n",
    "def feed_forward(tags_dict,A,B,vocab_dict,text,best_probs,h_unk=False):\n",
    "\n",
    "    best_paths = np.zeros((len(tags_dict),len(text)),dtype=int)\n",
    "\n",
    "    num_tags = len(tags_dict)\n",
    "    #iterate over the words in the text\n",
    "    for t in range(1,len(text)):\n",
    "\n",
    "        #iterate over the tags for the word\n",
    "        for j in range(num_tags):\n",
    "            best_prob = float('-inf')\n",
    "            best_path = None\n",
    "\n",
    "            #iterate over the tags for the previous word\n",
    "            for i in range(num_tags):\n",
    "                #handle unknown words\n",
    "                try :\n",
    "                    prob = best_probs[i,t-1]+math.log(A[j,i])+math.log(B[j,vocab_dict[text[t]]])\n",
    "                except KeyError:\n",
    "                    if h_unk:\n",
    "                        if tags_dict[handle_unk_words(text[t])]==j:\n",
    "                            bj = 1\n",
    "                        else:\n",
    "                            bj = 1e-8\n",
    "                        prob = best_probs[i,t-1]+math.log(A[j,i])+math.log(bj)\n",
    "                    else:\n",
    "                        prob = best_probs[i,t-1]+math.log(A[j,i])+math.log(1e-10)\n",
    "                if prob>best_prob:\n",
    "                    best_prob = prob\n",
    "                    best_path = i\n",
    "            \n",
    "            best_probs[j,t] = best_prob\n",
    "            best_paths[j,t] = best_path\n",
    "\n",
    "    return best_probs, best_paths\n",
    "\n",
    "best_probs, best_paths = feed_forward(tags_dict,A,B,vocab_dict,text,best_probs,h_unk=True)\n",
    "pd.DataFrame(best_probs[:5], columns = text[:5], index = list(tags_dict.keys())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Viterbi backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRP', 'VB', 'MD', 'NN']"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feed_backward(best_probs,best_paths,tags_dict):\n",
    "    m = best_probs.shape[1]\n",
    "    z = [0]*m\n",
    "    tags = list(tags_dict.keys())\n",
    "\n",
    "    z[-1]=np.argmax(best_probs[:,-1])\n",
    "    for t in range(m-1,0,-1):\n",
    "        z[t-1] = best_paths[z[t],t]\n",
    "\n",
    "    T = [tags[i] for i in z]\n",
    "\n",
    "    return T\n",
    "\n",
    "T = feed_backward(best_probs,best_paths,tags_dict)\n",
    "T\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together - **Viterbi algo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_pred(tags_dict,A,B,vocab_dict,text,h_unk=False):\n",
    "    best_probs = initialize(tags_dict,A,B,vocab_dict,text)\n",
    "    best_probs, best_paths = feed_forward(tags_dict,A,B,vocab_dict,text,best_probs,h_unk)\n",
    "\n",
    "    T = feed_backward(best_probs,best_paths,tags_dict)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence:  we are going to watch a football match , do you want to join us ? \n",
      "Tags: \n",
      "we         : PRP\n",
      "are        : VBP\n",
      "going      : PRP\n",
      "to         : TO\n",
      "watch      : NN\n",
      "a          : DT\n",
      "football   : NN\n",
      "match      : NN\n",
      ",          : ,\n",
      "do         : VBP\n",
      "you        : PRP\n",
      "want       : VB\n",
      "to         : TO\n",
      "join       : VB\n",
      "us         : PRP\n",
      "?          : ``\n"
     ]
    }
   ],
   "source": [
    "#Exemple \n",
    "sentence = \"we are going to watch a football match , do you want to join us ?\"\n",
    "print(\"Input sentence: \", sentence,'\\nTags: ')\n",
    "vit_pred = viterbi_pred(tags_dict,A,B,vocab_dict,sentence.split())\n",
    "for word, tag in zip(sentence.split(), vit_pred):\n",
    "    print(f\"{word.ljust(10)} : {tag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test data to feeature and target sets\n",
    "X_test = [[x[0] for x in sentence] for sentence in test_data]\n",
    "y_test = [[x[1] for x in sentence] for sentence in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy without handling unkown words : 0.7540101815387571\n",
      "The accuracy with handling unkown words    : 0.7751416770723274\n"
     ]
    }
   ],
   "source": [
    "#Computing the accuracy\n",
    "def accuracy(X_test,y_test,tags_dict,A,B,vocab_dict,h_unk=False):\n",
    "    accuracy = 0\n",
    "    S = 0\n",
    "    for i in range(len(X_test)):\n",
    "        pred = viterbi_pred(tags_dict,A,B,vocab_dict,X_test[i],h_unk)\n",
    "\n",
    "        for j in range(len(pred)):\n",
    "            if pred[j] == y_test[i][j]:\n",
    "                accuracy+=1\n",
    "            S+=1\n",
    "\n",
    "    return accuracy/S\n",
    "\n",
    "print(\"The accuracy without handling unkown words :\",accuracy(X_test,y_test,tags_dict,A,B,vocab_dict))\n",
    "print(\"The accuracy with handling unkown words    :\",accuracy(X_test,y_test,tags_dict,A,B,vocab_dict,True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
